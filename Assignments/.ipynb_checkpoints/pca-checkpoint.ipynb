{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principle Component Analysis\n",
    "- **Unsupervised** learning model, meaning that unlike supervised learning models, we are working with unlabeled data.\n",
    "    - You can confirm accuracies with supervised models but cannot with unsupervised models\n",
    "- The PCA plot is used to visualise correlations in a 2d graph \n",
    "- Tight clusters indicate highe correlation\n",
    "- The number of dimenions are reduced so that multiple so that patterns in correlation between features can be easily identified \n",
    "- In other words, PCA aims to find the directions of maximum variance in high-dimensional data and projects it onto a new subspace with equal or fewer dimensions than the original one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "1. [ ] Import your PCA data into a dataframe. Name the columns `PC1`, `PC2`, `PC3`, and `PC4`.  \n",
    "2. [ ] Drop PC3 and PC4 columns.\n",
    "3. [ ] Split your scaled data (currently stored in `scaled_X` and `labels`) into training and testing data using `train_test_split()`.  \n",
    "4. [ ] Split your PCA data (currently stored in `X_with_pca` and `labels`) into training and testing sets using `train_test_split()`.\n",
    "5. [ ] Create two `DecisionTreeClassifier` objects. Store one in `pca_clf` and one in `reg_clf`.\n",
    "6. [ ] Fit each model on their respective datasets, and make predictions from each. Compare the accuracy of each. Was the performance of the model fitted using the 2-dimensional PCA data of comparable performance? How would you tell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: *Initialise dataframe*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>Region</th>\n",
       "      <th>Fresh</th>\n",
       "      <th>Milk</th>\n",
       "      <th>Grocery</th>\n",
       "      <th>Frozen</th>\n",
       "      <th>Detergents_Paper</th>\n",
       "      <th>Delicassen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12669</td>\n",
       "      <td>9656</td>\n",
       "      <td>7561</td>\n",
       "      <td>214</td>\n",
       "      <td>2674</td>\n",
       "      <td>1338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7057</td>\n",
       "      <td>9810</td>\n",
       "      <td>9568</td>\n",
       "      <td>1762</td>\n",
       "      <td>3293</td>\n",
       "      <td>1776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6353</td>\n",
       "      <td>8808</td>\n",
       "      <td>7684</td>\n",
       "      <td>2405</td>\n",
       "      <td>3516</td>\n",
       "      <td>7844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Channel  Region  Fresh  Milk  Grocery  Frozen  Detergents_Paper  Delicassen\n",
       "0        2       3  12669  9656     7561     214              2674        1338\n",
       "1        2       3   7057  9810     9568    1762              3293        1776\n",
       "2        2       3   6353  8808     7684    2405              3516        7844"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data\n",
    "pca_df = pd.read_csv('../Datasets/Wholesale_customers_data.csv')\n",
    "pca_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: *Data Scaling & Transform*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/tom/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.44865163,  0.59066829,  0.05293319, ..., -0.58936716,\n",
       "        -0.04356873, -0.06633906],\n",
       "       [ 1.44865163,  0.59066829, -0.39130197, ..., -0.27013618,\n",
       "         0.08640684,  0.08915105],\n",
       "       [ 1.44865163,  0.59066829, -0.44702926, ..., -0.13753572,\n",
       "         0.13323164,  2.24329255],\n",
       "       ...,\n",
       "       [ 1.44865163,  0.59066829,  0.20032554, ..., -0.54337975,\n",
       "         2.51121768,  0.12145607],\n",
       "       [-0.69029709,  0.59066829, -0.13538389, ..., -0.41944059,\n",
       "        -0.56977032,  0.21304614],\n",
       "       [-0.69029709,  0.59066829, -0.72930698, ..., -0.62009417,\n",
       "        -0.50488752, -0.52286938]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling\n",
    "scaler = StandardScaler(copy = True, with_mean=True, with_std=True)\n",
    "scaler.fit(pca_df)\n",
    "scaled_df = scaler.transform(pca_df)\n",
    "scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: *PCA Model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance for Principal Component 0: 0.38750122911592594\n",
      "Explained Variance for Principal Component 1: 0.22374587951038902\n",
      "Explained Variance for Principal Component 2: 0.12647173452305818\n",
      "Explained Variance for Principal Component 3: 0.09229903718659851\n",
      "Explained Variance for Principal Component 4: 0.06957904970880047\n",
      "Explained Variance for Principal Component 5: 0.05741354435314432\n",
      "Explained Variance for Principal Component 6: 0.03514075682001749\n",
      "Explained Variance for Principal Component 7: 0.007848768782065967\n"
     ]
    }
   ],
   "source": [
    "# Initialise the model\n",
    "pca = PCA() \n",
    "\n",
    "# Fit the model with scaled data\n",
    "pca.fit(scaled_df) \n",
    "\n",
    "# Transform the scaled data\n",
    "pca_transformed = pca.transform(scaled_df) \n",
    "\n",
    "# enumerate through \"pca_transformed.explained_variance_ratio_\"\n",
    "# to see the amount of variance captured by each Principal Component\n",
    "for ind, var in enumerate(pca.explained_variance_ratio_):\n",
    "\tprint(f'Explained Variance for Principal Component {ind}: {var}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3.1: *Dropping Principle Components*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Principle Components into a Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38750123 0.22374588 0.12647173 0.09229904 0.06957905 0.05741354\n",
      " 0.03514076 0.00784877]\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCA1</th>\n",
       "      <th>PCA2</th>\n",
       "      <th>PCA3</th>\n",
       "      <th>PCA4</th>\n",
       "      <th>PCA5</th>\n",
       "      <th>PCA6</th>\n",
       "      <th>PCA7</th>\n",
       "      <th>PCA8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PCA1, PCA2, PCA3, PCA4, PCA5, PCA6, PCA7, PCA8]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_pca_df(values_list):\n",
    "    # create empty df     \n",
    "    df_pca = pd.DataFrame()\n",
    "    \n",
    "    # loop through pricniple components    \n",
    "    for i in range(len(values_list)):\n",
    "        # feature name\n",
    "        feature = \"PCA\" + str(i+1)\n",
    "        # principle component explained variance ratio value\n",
    "        value = values_list[i]\n",
    "        # create new feature with corresponding value\n",
    "        df_pca[feature] = value \n",
    "    \n",
    "    return df_pca\n",
    "\n",
    "df_pca = create_pca_df(pca.explained_variance_ratio_)\n",
    "df_pca"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
